{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1 style=\"color:#1398A1\">TRAINING<h1>\n",
   "id": "7f02091917cea351"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3 style=\"color:#CCC229\">LIBRAIRIES IMPORT<h3>\n",
   "id": "de89cb123b88dcba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:06:12.300296402Z",
     "start_time": "2026-01-25T20:06:12.181760910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajouter le dossier src au path\n",
    "src_path = Path(\"..\") / \"..\"\n",
    "sys.path.append(str(src_path))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import mlflow\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.utils import safe_mean\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "from huggingface_hub import hf_hub_download\n",
    "from env.snake_env import SnakeEnv\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_HUB_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"‚ö†Ô∏è Variable HF_HUB_TOKEN manquante.\")"
   ],
   "id": "874a7fa38b5c5af3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3 style=\"color:#CCC229\">TRAIN FUNCTION<h3>",
   "id": "9fd7f5440c4adc1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:36:54.993631409Z",
     "start_time": "2026-01-25T20:36:54.931912791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_snake_model_data(uuid: str, hf_repo_id: str):\n",
    "    # 1. S√©curit√© Token\n",
    "    token = os.getenv(\"HF_HUB_TOKEN\")\n",
    "    if not token:\n",
    "        print(\"‚ùå Erreur : HF_HUB_TOKEN manquant.\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"üîç Scan du d√©p√¥t pour trouver l'UUID : {uuid} ...\")\n",
    "    api = HfApi(token=token)\n",
    "\n",
    "    try:\n",
    "        # 2. On r√©cup√®re la liste COMPL√àTE des fichiers du repo\n",
    "        # Cela nous donne une liste de cha√Ænes : [\"5x5/abc.../model.zip\", \"10x10/xyz.../metadata.json\", ...]\n",
    "        all_files = api.list_repo_files(repo_id=hf_repo_id, repo_type=\"model\", token=token)\n",
    "\n",
    "        # 3. On cherche l'aiguille dans la botte de foin\n",
    "        target_path = None\n",
    "        for filename in all_files:\n",
    "            # On cherche le fichier metadata qui contient notre UUID dans son chemin\n",
    "            if uuid in filename and filename.endswith(\"metadata.json\"):\n",
    "                target_path = filename\n",
    "                break\n",
    "\n",
    "        if not target_path:\n",
    "            print(f\"‚ùå Impossible de trouver un dossier contenant l'UUID {uuid}\")\n",
    "            return None, None\n",
    "\n",
    "        # target_path vaut maintenant quelque chose comme : \"5x5/20a0ecbd.../metadata.json\"\n",
    "        print(f\"üìç Fichier trouv√© : {target_path}\")\n",
    "\n",
    "        # 4. On t√©l√©charge ce fichier pr√©cis\n",
    "        local_meta_path = hf_hub_download(\n",
    "            repo_id=hf_repo_id,\n",
    "            filename=target_path,\n",
    "            repo_type=\"model\",\n",
    "            token=token\n",
    "        )\n",
    "\n",
    "        # 5. On lit la grid_size (pour √™tre s√ªr)\n",
    "        with open(local_meta_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            grid_size = data.get(\"grid_size\")\n",
    "\n",
    "        # 6. On d√©duit le chemin du mod√®le .zip\n",
    "        # On remplace juste \"metadata.json\" par \"model.zip\" dans le chemin qu'on a trouv√©\n",
    "        model_path_in_repo = target_path.replace(\"metadata.json\", \"model.zip\")\n",
    "\n",
    "        print(f\"üì• T√©l√©chargement du mod√®le : {model_path_in_repo}\")\n",
    "        local_model_path = hf_hub_download(\n",
    "            repo_id=hf_repo_id,\n",
    "            filename=model_path_in_repo,\n",
    "            repo_type=\"model\",\n",
    "            token=token\n",
    "        )\n",
    "\n",
    "        # 7. Chargement final\n",
    "        agent = PPO.load(local_model_path)\n",
    "        print(f\"‚úÖ Succ√®s ! Agent charg√© (Grille {grid_size}x{grid_size})\")\n",
    "\n",
    "        return agent, grid_size\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du scan/chargement : {e}\")\n",
    "        return None, None"
   ],
   "id": "d05770f4047d1cad",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:21:06.425065699Z",
     "start_time": "2026-01-25T20:21:06.386700406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_snake_models(\n",
    "    grid_size_filter: int = None,\n",
    "    sort_by: str = \"date\",  #\n",
    "    hf_repo_id: str = \"Lategardener/snake-rl-models\"\n",
    "):\n",
    "    print(f\"üîç Recherche des mod√®les dans {hf_repo_id}...\")\n",
    "    api = HfApi(token=hf_token)\n",
    "\n",
    "    # 1. R√©cup√©rer tous les fichiers du repo\n",
    "    all_files = api.list_repo_files(repo_id=hf_repo_id, repo_type=\"model\")\n",
    "\n",
    "    # 2. Filtrer uniquement les fichiers metadata.json\n",
    "    meta_files = [f for f in all_files if f.endswith(\"metadata.json\")]\n",
    "\n",
    "    models_data = []\n",
    "\n",
    "    # 3. Lire chaque fichier metadata (C'est rapide car ce sont de petits fichiers JSON)\n",
    "    for meta_file in meta_files:\n",
    "        try:\n",
    "            # T√©l√©chargement en cache\n",
    "            local_path = hf_hub_download(repo_id=hf_repo_id, filename=meta_file, repo_type=\"model\", token=hf_token)\n",
    "\n",
    "            with open(local_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Filtrage par taille de grille\n",
    "            model_grid = data.get(\"grid_size\")\n",
    "            if grid_size_filter is not None and model_grid != grid_size_filter:\n",
    "                continue\n",
    "\n",
    "            # Parsing de la date pour le tri\n",
    "            date_str = data.get(\"date\", \"\")\n",
    "            try:\n",
    "                dt_object = datetime.strptime(date_str, \"%d/%m/%Y %H:%M:%S\")\n",
    "            except ValueError:\n",
    "                dt_object = datetime.min\n",
    "\n",
    "            data[\"_dt_object\"] = dt_object # Stock√© pour le tri interne\n",
    "            models_data.append(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur lecture {meta_file}: {e}\")\n",
    "\n",
    "    # 4. Tri\n",
    "    if sort_by == \"date\":\n",
    "        models_data.sort(key=lambda x: x[\"_dt_object\"], reverse=True) # Plus r√©cent en premier\n",
    "    elif sort_by == \"reward\":\n",
    "        # On met -inf si pas de reward pour qu'ils soient √† la fin\n",
    "        models_data.sort(key=lambda x: x.get(\"final_mean_reward\") or float('-inf'), reverse=True)\n",
    "\n",
    "    # 5. Affichage Tableau\n",
    "    print(f\"\\n{' ' * 12} {'MODELE (UUID)'} {' ' * 17} || {' ' * 15} {'DESCRIPTION'}\")\n",
    "    print(\"-\" * 110)\n",
    "\n",
    "    for m in models_data:\n",
    "        uuid_display = f\"{m.get('grid_size'):02d}x{m.get('grid_size'):02d} / {m.get('uuid')}\"\n",
    "\n",
    "        # Construction de la description\n",
    "        algo = m.get('algorithm', 'N/A')\n",
    "        date = m.get('date', 'N/A')\n",
    "        rew = m.get('final_mean_reward')\n",
    "        rew_str = f\"{rew:.2f}\" if isinstance(rew, (int, float)) else \"N/A\"\n",
    "\n",
    "        desc = f\"Algo: {algo} | Date: {date} | Reward: {rew_str}\"\n",
    "\n",
    "        print(f\"{uuid_display} || {desc}\")\n",
    "\n",
    "    print(\"-\" * 110)\n",
    "    print(f\"‚úÖ Nombre de mod√®les trouv√©s : {len(models_data)}\")"
   ],
   "id": "dd4495c16f7e0100",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:41:04.588027761Z",
     "start_time": "2026-01-25T19:41:04.562308434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------------------\n",
    "# Callback\n",
    "# ------------------------------------------\n",
    "class MLflowLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "    def _on_step(self) -> bool:\n",
    "        return True\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        try:\n",
    "            logger_values = getattr(self.logger, \"name_to_value\", {})\n",
    "            metrics = {k: float(v) for k, v in logger_values.items()}\n",
    "            if hasattr(self.model, \"ep_info_buffer\") and len(self.model.ep_info_buffer) > 0:\n",
    "                metrics[\"rollout/ep_rew_mean\"] = float(safe_mean([ep[\"r\"] for ep in self.model.ep_info_buffer]))\n",
    "                metrics[\"rollout/ep_len_mean\"] = float(safe_mean([ep[\"l\"] for ep in self.model.ep_info_buffer]))\n",
    "            if metrics:\n",
    "                mlflow.log_metrics(metrics, step=self.num_timesteps)\n",
    "        except Exception:\n",
    "            pass"
   ],
   "id": "555460c9d161bde7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T19:58:35.894368734Z",
     "start_time": "2026-01-25T19:58:35.826147161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# Wrapper MLflow pour Hugging Face\n",
    "# ---------------------------------------------------------\n",
    "class SnakeHFModel(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    Classe Wrapper qui permet √† MLflow de savoir comment charger et utiliser\n",
    "    ton mod√®le stock√© sur Hugging Face.\n",
    "    \"\"\"\n",
    "    def __init__(self, repo_id: str, subfolder: str):\n",
    "        # On sauvegarde les infos pour retrouver le mod√®le plus tard\n",
    "        self.repo_id = repo_id\n",
    "        self.subfolder = subfolder\n",
    "        self.model = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # Cette m√©thode est ex√©cut√©e quand on charge le mod√®le via mlflow.pyfunc.load_model()\n",
    "        from huggingface_hub import hf_hub_download\n",
    "        from stable_baselines3 import PPO\n",
    "\n",
    "        print(f\"üì• Chargement du contexte mod√®le depuis {self.repo_id}...\")\n",
    "\n",
    "        # T√©l√©chargement du fichier physique\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=self.repo_id,\n",
    "            filename=f\"{self.subfolder}/model.zip\"\n",
    "        )\n",
    "\n",
    "        # Chargement en m√©moire\n",
    "        self.model = PPO.load(model_path)\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"\n",
    "        MLflow exige que le param√®tre s'appelle 'model_input'.\n",
    "        Ici, model_input correspondra √† ton observation.\n",
    "        \"\"\"\n",
    "        action, _ = self.model.predict(model_input)\n",
    "        return action"
   ],
   "id": "e57b81486dd38bd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cytech/programmation/AI/snake_rl/.venv/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-25T19:58:55.405473117Z",
     "start_time": "2026-01-25T19:58:55.273698350Z"
    }
   },
   "source": [
    "def train_snake(\n",
    "    timesteps: int = 100_000,\n",
    "    grid_size: int = None,      # Optionnel si base_uuid est fourni\n",
    "    n_envs: int = 4,\n",
    "    algorithm: str = \"PPO\",\n",
    "    hf_repo_id: str = \"Lategardener/snake-rl-models\",\n",
    "    base_uuid: str = None       # L'UUID du mod√®le parent (d√©clenche le fine-tuning)\n",
    "):\n",
    "    # --- A. Initialisation ---\n",
    "    now = datetime.now()\n",
    "    readable_date = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    date_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    new_agent_uuid = str(uuid.uuid4())\n",
    "\n",
    "    # --- B. Logique de Chargement (Le Cerveau) ---\n",
    "    agent = None\n",
    "    is_finetuning = False\n",
    "\n",
    "    if base_uuid:\n",
    "        # Mode FINE-TUNING : On va chercher le mod√®le et ses infos\n",
    "        try:\n",
    "            agent, loaded_grid_size = load_snake_model_data(base_uuid, hf_repo_id)\n",
    "\n",
    "            # On √©crase la grid_size avec celle du mod√®le charg√© (c'est la v√©rit√© terrain)\n",
    "            grid_size = loaded_grid_size\n",
    "            is_finetuning = True\n",
    "            mode_label = \"FINE-TUNING\"\n",
    "            print(f\"‚úÖ Mod√®le charg√© avec succ√®s. Reprise sur grille {grid_size}x{grid_size}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Impossible de charger le mod√®le {base_uuid} : {e}\")\n",
    "            return # On arr√™te tout pour ne pas lancer un training vide par erreur\n",
    "    else:\n",
    "        # Mode NEW TRAINING\n",
    "        if grid_size is None:\n",
    "            raise ValueError(\"‚ö†Ô∏è Vous devez sp√©cifier 'grid_size' pour un nouvel entra√Ænement.\")\n",
    "        mode_label = \"NEW_TRAINING\"\n",
    "        print(f\"‚ú® Cr√©ation d'un nouvel agent vierge sur grille {grid_size}x{grid_size}.\")\n",
    "\n",
    "    # --- C. Configuration MLflow ---\n",
    "    run_name = f\"{mode_label}_{date_str}_{new_agent_uuid[:8]}\"\n",
    "    mlflow.set_experiment(f\"Snake_{grid_size}x{grid_size}\")\n",
    "\n",
    "    print(f\"\\nüöÄ D√©marrage Run MLflow : {run_name}\")\n",
    "    print(f\"üÜî Nouvel ID : {new_agent_uuid}\")\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "        # Tags\n",
    "        mlflow.set_tag(\"agent_uuid\", new_agent_uuid)\n",
    "        mlflow.set_tag(\"hf_repo\", hf_repo_id)\n",
    "        mlflow.set_tag(\"run_type\", \"finetuning\" if is_finetuning else \"fresh\")\n",
    "        if base_uuid:\n",
    "            mlflow.set_tag(\"parent_model_uuid\", base_uuid)\n",
    "\n",
    "        # Params\n",
    "        mlflow.log_params({\n",
    "            \"algorithm\": algorithm,\n",
    "            \"grid_size\": grid_size,\n",
    "            \"timesteps_added\": timesteps,\n",
    "            \"base_model\": base_uuid if base_uuid else \"None\"\n",
    "        })\n",
    "\n",
    "        # --- D. Environnement & Agent ---\n",
    "        env = make_vec_env(lambda: Monitor(SnakeEnv(grid_size=grid_size, render_mode=None)), n_envs=n_envs)\n",
    "\n",
    "        if is_finetuning:\n",
    "            agent.set_env(env) # Connexion du vieux cerveau au nouveau corps\n",
    "        else:\n",
    "            agent = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "        # --- E. Entra√Ænement ---\n",
    "        agent.learn(\n",
    "            total_timesteps=timesteps,\n",
    "            callback=MLflowLoggingCallback(),\n",
    "            reset_num_timesteps=not is_finetuning # False si fine-tuning pour continuer les courbes\n",
    "        )\n",
    "\n",
    "        # --- F. Sauvegarde & Upload ---\n",
    "        print(\"\\nüíæ Sauvegarde et Upload...\")\n",
    "        with tempfile.TemporaryDirectory() as temp_dir_str:\n",
    "            temp_dir = Path(temp_dir_str)\n",
    "\n",
    "            # 1. Save Local\n",
    "            agent.save(temp_dir / \"model.zip\")\n",
    "\n",
    "            # 2. Metadata\n",
    "            hf_folder = f\"{grid_size}x{grid_size}/{new_agent_uuid}\"\n",
    "            final_reward = safe_mean([ep[\"r\"] for ep in agent.ep_info_buffer]) if agent.ep_info_buffer else None\n",
    "\n",
    "            metadata = {\n",
    "                \"uuid\": new_agent_uuid,\n",
    "                \"type\": \"finetuned\" if is_finetuning else \"fresh\",\n",
    "                \"parent_uuid\": base_uuid,\n",
    "                \"grid_size\": grid_size,\n",
    "                \"algorithm\": algorithm,\n",
    "                \"date\": readable_date,\n",
    "                \"final_mean_reward\": final_reward,\n",
    "                \"hf_folder\": hf_folder,\n",
    "                \"mlflow_run_id\": run.info.run_id\n",
    "            }\n",
    "\n",
    "            with open(temp_dir / \"metadata.json\", \"w\") as f:\n",
    "                json.dump(metadata, f, indent=4)\n",
    "\n",
    "            # 3. Upload HF\n",
    "            api = HfApi(token=hf_token)\n",
    "            api.create_repo(repo_id=hf_repo_id, repo_type=\"model\", exist_ok=True, private=True)\n",
    "            api.upload_folder(\n",
    "                folder_path=str(temp_dir),\n",
    "                path_in_repo=hf_folder,\n",
    "                repo_id=hf_repo_id,\n",
    "                commit_message=f\"Add {mode_label} model {new_agent_uuid}\"\n",
    "            )\n",
    "\n",
    "            # 4. Note MLflow\n",
    "            hf_url = f\"https://huggingface.co/{hf_repo_id}/tree/main/{hf_folder}\"\n",
    "            zip_url = f\"https://huggingface.co/{hf_repo_id}/resolve/main/{hf_folder}/model.zip?download=true\"\n",
    "\n",
    "            parent_info = f\"**Base Modele :** `{base_uuid}`\" if base_uuid else \"\"\n",
    "\n",
    "            note = textwrap.dedent(f\"\"\"\\\n",
    "                ### {mode_label} - Snake {grid_size}x{grid_size}\n",
    "\n",
    "                ID : {new_agent_uuid}\n",
    "                Date : {readable_date}\n",
    "                {parent_info}\n",
    "                Reward Finale : {final_reward if final_reward else 'N/A'}\n",
    "\n",
    "                ---\n",
    "                - [Telecharger Modele]({zip_url})\n",
    "                - [Voir Fichiers]({hf_url})\n",
    "                \"\"\")\n",
    "\n",
    "            mlflow.set_tag(\"mlflow.note.content\", note)\n",
    "            mlflow.set_tag(\"model_url\", hf_url)\n",
    "\n",
    "            # 5. Model Registry (Logique)\n",
    "            model_wrapper = SnakeHFModel(repo_id=hf_repo_id, subfolder=hf_folder)\n",
    "            model_info = mlflow.pyfunc.log_model(artifact_path=\"snake_model\", python_model=model_wrapper)\n",
    "            mlflow.register_model(model_uri=model_info.model_uri, name=f\"Snake_{grid_size}x{grid_size}\")\n",
    "\n",
    "            print(f\"‚úÖ Termin√© ! Nouveau mod√®le : {new_agent_uuid}\")\n",
    "\n",
    "    return agent, new_agent_uuid"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:18:37.438075340Z",
     "start_time": "2026-01-25T20:18:37.398676840Z"
    }
   },
   "cell_type": "code",
   "source": "train_snake(timesteps=100000, grid_size=5, n_envs=8, algorithm=\"PPO\")",
   "id": "715860182ef1f87d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:38:40.357897819Z",
     "start_time": "2026-01-25T20:37:01.803220362Z"
    }
   },
   "cell_type": "code",
   "source": "train_snake(timesteps=100000, grid_size=5, n_envs=8, algorithm=\"PPO\", base_uuid=\"20a0ecbd-360b-401c-9977-a6bfaec87e23\")\n",
   "id": "d95e2d7cee113232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scan du d√©p√¥t pour trouver l'UUID : 20a0ecbd-360b-401c-9977-a6bfaec87e23 ...\n",
      "üìç Fichier trouv√© : 5x5/20a0ecbd-360b-401c-9977-a6bfaec87e23/metadata.json\n",
      "üì• T√©l√©chargement du mod√®le : 5x5/20a0ecbd-360b-401c-9977-a6bfaec87e23/model.zip\n",
      "‚úÖ Succ√®s ! Agent charg√© (Grille 5x5)\n",
      "‚úÖ Mod√®le charg√© avec succ√®s. Reprise sur grille 5x5.\n",
      "\n",
      "üöÄ D√©marrage Run MLflow : FINE-TUNING_20260125_213701_b3293178\n",
      "üÜî Nouvel ID : b3293178-4918-4855-ab65-4d2980e883ac\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.28     |\n",
      "|    ep_rew_mean     | 0.109    |\n",
      "| time/              |          |\n",
      "|    fps             | 7345     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.54       |\n",
      "|    ep_rew_mean          | 0.328      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2450       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01921218 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.847     |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0776     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.251      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.39        |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016345315 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0748      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.32        |\n",
      "|    ep_rew_mean          | 0.684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1751        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015578415 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 0.373       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.3         |\n",
      "|    ep_rew_mean          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1736        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013935305 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.69        |\n",
      "|    ep_rew_mean          | 0.842       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1653        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011923952 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.513       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.7          |\n",
      "|    ep_rew_mean          | 1.13         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112132225 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.325        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 0.582        |\n",
      "------------------------------------------\n",
      "\n",
      "üíæ Sauvegarde et Upload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            \n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  175kB /  175kB,  292kB/s  \n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  175kB /  175kB,  175kB/s  \n",
      "New Data Upload: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  175kB /  175kB,  175kB/s  \n",
      "2026/01/25 21:38:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/25 21:38:38 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp8jaf9ckt/model, flavor: python_function). Fall back to return ['cloudpickle==3.1.2']. Set logging level to DEBUG to see the full traceback. \n",
      "Registered model 'Snake_5x5' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'Snake_5x5'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Termin√© ! Nouveau mod√®le : b3293178-4918-4855-ab65-4d2980e883ac\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<stable_baselines3.ppo.ppo.PPO at 0x728844bd8e20>,\n",
       " 'b3293178-4918-4855-ab65-4d2980e883ac')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:21:10.314874639Z",
     "start_time": "2026-01-25T20:21:09.633675018Z"
    }
   },
   "cell_type": "code",
   "source": "list_snake_models()",
   "id": "7ebff0f514f41c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recherche des mod√®les dans Lategardener/snake-rl-models...\n",
      "\n",
      "             MODELE (UUID)                   ||                 DESCRIPTION\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "05x05 / 20a0ecbd-360b-401c-9977-a6bfaec87e23 || Algo: PPO | Date: 25/01/2026 20:58:59 | Reward: -0.06\n",
      "05x05 / 6ee34c5d-af9e-48a6-b64f-1b1cc8a0080a || Algo: PPO | Date: 25/01/2026 20:41:04 | Reward: 0.01\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "‚úÖ Nombre de mod√®les trouv√©s : 2\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
